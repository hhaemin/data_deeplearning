{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM0lWl1+9lyinYKlFiDw0nF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hhaemin/data_deeplearning/blob/main/plant_healthy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 식물잎의 사진으로 질병분류"
      ],
      "metadata": {
        "id": "G4PKOJCvtPR1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 파일 정리"
      ],
      "metadata": {
        "id": "yy-1KA4ClPOq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6secG9De1nb",
        "outputId": "274a8210-15b8-46b9-cc25-29b457a117a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq '/content/drive/MyDrive/dataset.zip' -d './dataset'"
      ],
      "metadata": {
        "id": "j_BM9Liif5Qt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "orginal_dataset_dir = './dataset'\n",
        "classes_list = os.listdir(orginal_dataset_dir)\n",
        "\n",
        "base_dir = './splitted'\n",
        "os.mkdir(base_dir)"
      ],
      "metadata": {
        "id": "MDDxLgxpibw3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.mkdir(train_dir)\n",
        "validation_dir = os.path.join(base_dir, 'val')\n",
        "os.mkdir(validation_dir)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.mkdir(test_dir)\n",
        "\n",
        "for cls in classes_list:\n",
        "  os.mkdir(os.path.join(train_dir, cls))\n",
        "  os.mkdir(os.path.join(validation_dir, cls))\n",
        "  os.mkdir(os.path.join(test_dir, cls))"
      ],
      "metadata": {
        "id": "HammuhHEit1G"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "for cls in classes_list:\n",
        "  path = os.path.join(orginal_dataset_dir, cls)\n",
        "  fnames = os.listdir(path)\n",
        "\n",
        "  train_size = math.floor(len(fnames) * 0.6)\n",
        "  validation_size = math.floor(len(fnames) * 0.2)\n",
        "  test_size = math.floor(len(fnames) * 0.2)\n",
        "\n",
        "  train_fnames = fnames[:train_size]\n",
        "  print(\"Train size(\",cls,\"): \", len(train_fnames))\n",
        "  for fname in train_fnames:\n",
        "    src = os.path.join(path, fname)\n",
        "    dst = os.path.join(os.path.join(train_dir, cls), fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "  validation_fnames = fnames[train_size:(validation_size + train_size)]\n",
        "  print(\"Validation size(\",cls,\"): \", len(validation_fnames))\n",
        "  for fname in validation_fnames:\n",
        "    src = os.path.join(path, fname)\n",
        "    dst = os.path.join(os.path.join(validation_dir, cls), fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "  test_fnames = fnames[(train_size+validation_size):(validation_size+train_size+test_size)]\n",
        "  print(\"Test size(\",cls,\"): \", len(test_fnames))\n",
        "  for fname in test_fnames:\n",
        "    src = os.path.join(path, fname)\n",
        "    dst = os.path.join(os.path.join(train_dir, cls), fname)\n",
        "    shutil.copyfile(src, dst)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD3I3J0XjdBI",
        "outputId": "62630f4b-72fc-4826-e6c8-6503b9c18ec5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size( Tomato___Tomato_Yellow_Leaf_Curl_Virus ):  3214\n",
            "Validation size( Tomato___Tomato_Yellow_Leaf_Curl_Virus ):  1071\n",
            "Test size( Tomato___Tomato_Yellow_Leaf_Curl_Virus ):  1071\n",
            "Train size( Potato___healthy ):  91\n",
            "Validation size( Potato___healthy ):  30\n",
            "Test size( Potato___healthy ):  30\n",
            "Train size( Tomato___Tomato_mosaic_virus ):  223\n",
            "Validation size( Tomato___Tomato_mosaic_virus ):  74\n",
            "Test size( Tomato___Tomato_mosaic_virus ):  74\n",
            "Train size( Corn___Cercospora_leaf_spot Gray_leaf_spot ):  307\n",
            "Validation size( Corn___Cercospora_leaf_spot Gray_leaf_spot ):  102\n",
            "Test size( Corn___Cercospora_leaf_spot Gray_leaf_spot ):  102\n",
            "Train size( Apple___Cedar_apple_rust ):  165\n",
            "Validation size( Apple___Cedar_apple_rust ):  55\n",
            "Test size( Apple___Cedar_apple_rust ):  55\n",
            "Train size( Potato___Late_blight ):  600\n",
            "Validation size( Potato___Late_blight ):  200\n",
            "Test size( Potato___Late_blight ):  200\n",
            "Train size( Corn___healthy ):  697\n",
            "Validation size( Corn___healthy ):  232\n",
            "Test size( Corn___healthy ):  232\n",
            "Train size( Cherry___Powdery_mildew ):  631\n",
            "Validation size( Cherry___Powdery_mildew ):  210\n",
            "Test size( Cherry___Powdery_mildew ):  210\n",
            "Train size( Tomato___Bacterial_spot ):  1276\n",
            "Validation size( Tomato___Bacterial_spot ):  425\n",
            "Test size( Tomato___Bacterial_spot ):  425\n",
            "Train size( Apple___Apple_scab ):  378\n",
            "Validation size( Apple___Apple_scab ):  126\n",
            "Test size( Apple___Apple_scab ):  126\n",
            "Train size( Corn___Common_rust ):  715\n",
            "Validation size( Corn___Common_rust ):  238\n",
            "Test size( Corn___Common_rust ):  238\n",
            "Train size( Peach___Bacterial_spot ):  1378\n",
            "Validation size( Peach___Bacterial_spot ):  459\n",
            "Test size( Peach___Bacterial_spot ):  459\n",
            "Train size( Tomato___Early_blight ):  600\n",
            "Validation size( Tomato___Early_blight ):  200\n",
            "Test size( Tomato___Early_blight ):  200\n",
            "Train size( Apple___healthy ):  987\n",
            "Validation size( Apple___healthy ):  329\n",
            "Test size( Apple___healthy ):  329\n",
            "Train size( Corn___Northern_Leaf_Blight ):  591\n",
            "Validation size( Corn___Northern_Leaf_Blight ):  197\n",
            "Test size( Corn___Northern_Leaf_Blight ):  197\n",
            "Train size( Grape___Leaf_blight_(Isariopsis_Leaf_Spot) ):  645\n",
            "Validation size( Grape___Leaf_blight_(Isariopsis_Leaf_Spot) ):  215\n",
            "Test size( Grape___Leaf_blight_(Isariopsis_Leaf_Spot) ):  215\n",
            "Train size( Tomato___Septoria_leaf_spot ):  1062\n",
            "Validation size( Tomato___Septoria_leaf_spot ):  354\n",
            "Test size( Tomato___Septoria_leaf_spot ):  354\n",
            "Train size( Grape___healthy ):  253\n",
            "Validation size( Grape___healthy ):  84\n",
            "Test size( Grape___healthy ):  84\n",
            "Train size( Cherry___healthy ):  512\n",
            "Validation size( Cherry___healthy ):  170\n",
            "Test size( Cherry___healthy ):  170\n",
            "Train size( Apple___Black_rot ):  372\n",
            "Validation size( Apple___Black_rot ):  124\n",
            "Test size( Apple___Black_rot ):  124\n",
            "Train size( Potato___Early_blight ):  600\n",
            "Validation size( Potato___Early_blight ):  200\n",
            "Test size( Potato___Early_blight ):  200\n",
            "Train size( Tomato___Target_Spot ):  842\n",
            "Validation size( Tomato___Target_Spot ):  280\n",
            "Test size( Tomato___Target_Spot ):  280\n",
            "Train size( Tomato___Spider_mites Two-spotted_spider_mite ):  1005\n",
            "Validation size( Tomato___Spider_mites Two-spotted_spider_mite ):  335\n",
            "Test size( Tomato___Spider_mites Two-spotted_spider_mite ):  335\n",
            "Train size( Tomato___healthy ):  954\n",
            "Validation size( Tomato___healthy ):  318\n",
            "Test size( Tomato___healthy ):  318\n",
            "Train size( Peach___healthy ):  216\n",
            "Validation size( Peach___healthy ):  72\n",
            "Test size( Peach___healthy ):  72\n",
            "Train size( Tomato___Leaf_Mold ):  571\n",
            "Validation size( Tomato___Leaf_Mold ):  190\n",
            "Test size( Tomato___Leaf_Mold ):  190\n",
            "Train size( Tomato___Late_blight ):  1145\n",
            "Validation size( Tomato___Late_blight ):  381\n",
            "Test size( Tomato___Late_blight ):  381\n",
            "Train size( Grape___Black_rot ):  708\n",
            "Validation size( Grape___Black_rot ):  236\n",
            "Test size( Grape___Black_rot ):  236\n",
            "Train size( Strawberry___Leaf_scorch ):  665\n",
            "Validation size( Strawberry___Leaf_scorch ):  221\n",
            "Test size( Strawberry___Leaf_scorch ):  221\n",
            "Train size( Strawberry___healthy ):  273\n",
            "Validation size( Strawberry___healthy ):  91\n",
            "Test size( Strawberry___healthy ):  91\n",
            "Train size( Grape___Esca_(Black_Measles) ):  829\n",
            "Validation size( Grape___Esca_(Black_Measles) ):  276\n",
            "Test size( Grape___Esca_(Black_Measles) ):  276\n",
            "Train size( Pepper,_bell___healthy ):  886\n",
            "Validation size( Pepper,_bell___healthy ):  295\n",
            "Test size( Pepper,_bell___healthy ):  295\n",
            "Train size( Pepper,_bell___Bacterial_spot ):  598\n",
            "Validation size( Pepper,_bell___Bacterial_spot ):  199\n",
            "Test size( Pepper,_bell___Bacterial_spot ):  199\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습하기"
      ],
      "metadata": {
        "id": "w2GU_Qd8lMVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "BATCH_SIZE = 256\n",
        "EPOCH = 30"
      ],
      "metadata": {
        "id": "QeKdJauxkU1l"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "transform_base = transforms.Compose([transforms.Resize((64,64)), transforms.ToTensor()])\n",
        "train_dataset = ImageFolder(root='./splitted/train', transform=transform_base)\n",
        "val_dataset = ImageFolder(root='./splitted/val', transform=transform_base)"
      ],
      "metadata": {
        "id": "bUqNlH-Ildfb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           shuffle=True,\n",
        "                                           num_workers=4)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
        "                                         batch_size=BATCH_SIZE,\n",
        "                                         shuffle=True,\n",
        "                                         num_workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chmL0mYNmbjE",
        "outputId": "741f4cf8-495c-453a-fa6f-97ac99afd1ad"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    super(Net, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "    self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "    self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "\n",
        "    self.fc1 = nn.Linear(4096, 512)\n",
        "    self.fc2 = nn.Linear(512, 33)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pool(x)\n",
        "    x = F.dropout(x, p=0.25, training=self.training)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pool(x)\n",
        "    x = F.dropout(x, p=0.25, training= self.training)\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pool(x)\n",
        "    x = F.dropout(x, p=0.25, training= self.training)\n",
        "\n",
        "    x = x.view(-1, 4096)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.dropout(x, p=0.5, training=self.training)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return F.log_softmax(x, dim=1)\n",
        "\n",
        "model_base = Net().to(DEVICE)\n",
        "optimizer = optim.Adam(model_base.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "teLXvE2OnDSR"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, optimizer):\n",
        "  model.train()\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = F.cross_entropy(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "Ghs_l8AloFQT"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader):\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "      data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "      output= model(data)\n",
        "\n",
        "      test_loss +=F.cross_entropy(output, target, reduction='sum').item()\n",
        "\n",
        "      pred = output.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "  return test_loss, test_accuracy "
      ],
      "metadata": {
        "id": "bhBn-ETkomgv"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import copy\n",
        "\n",
        "def train_baseline(model, train_loader, val_loader, optimizer, num_epochs = 30):\n",
        "  best_acc = 0.0\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "  for epoch in range(1, num_epochs + 1):\n",
        "    since = time.time()\n",
        "    train(model, train_loader, optimizer)\n",
        "    train_loss, train_acc = evaluate(model, train_loader)\n",
        "    val_loss, val_acc = evaluate(model, val_loader)\n",
        "\n",
        "    if val_acc > best_acc:\n",
        "      best_acc = val_acc\n",
        "      best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('-------------------epoch {} -------------------'.format(epoch))\n",
        "    print('train Loss: {:.4f}, Accuracy: {:.2f}%'.format(train_loss, train_acc))\n",
        "    print('val Loss: {:.4f}, Accuracy: {:.2f}%'.format(val_loss, val_acc))\n",
        "    print('Completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "  model.load_state_dict(best_model_wts)\n",
        "  return model\n",
        "\n",
        "base = train_baseline(model_base, train_loader, val_loader, optimizer, EPOCH)\n",
        "torch.save(base, 'baseline.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAe9L1_TpOD3",
        "outputId": "bb20e1c3-3602-4569-b45a-aeaeb82f4d34"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------epoch 1 -------------------\n",
            "train Loss: 0.6563, Accuracy: 79.67%\n",
            "val Loss: 0.7034, Accuracy: 78.06%\n",
            "Completed in 2m 9s\n",
            "-------------------epoch 2 -------------------\n",
            "train Loss: 0.4712, Accuracy: 85.31%\n",
            "val Loss: 0.5300, Accuracy: 83.38%\n",
            "Completed in 2m 18s\n",
            "-------------------epoch 3 -------------------\n",
            "train Loss: 0.4038, Accuracy: 87.89%\n",
            "val Loss: 0.4666, Accuracy: 85.77%\n",
            "Completed in 2m 25s\n",
            "-------------------epoch 4 -------------------\n",
            "train Loss: 0.3545, Accuracy: 89.27%\n",
            "val Loss: 0.4252, Accuracy: 87.24%\n",
            "Completed in 2m 20s\n",
            "-------------------epoch 5 -------------------\n",
            "train Loss: 0.3117, Accuracy: 91.02%\n",
            "val Loss: 0.3860, Accuracy: 88.42%\n",
            "Completed in 2m 16s\n",
            "-------------------epoch 6 -------------------\n",
            "train Loss: 0.2627, Accuracy: 92.12%\n",
            "val Loss: 0.3465, Accuracy: 89.40%\n",
            "Completed in 2m 10s\n",
            "-------------------epoch 7 -------------------\n",
            "train Loss: 0.2681, Accuracy: 91.80%\n",
            "val Loss: 0.3606, Accuracy: 88.42%\n",
            "Completed in 2m 13s\n",
            "-------------------epoch 8 -------------------\n",
            "train Loss: 0.2096, Accuracy: 93.69%\n",
            "val Loss: 0.3018, Accuracy: 90.22%\n",
            "Completed in 2m 27s\n",
            "-------------------epoch 9 -------------------\n",
            "train Loss: 0.2001, Accuracy: 94.00%\n",
            "val Loss: 0.2936, Accuracy: 90.84%\n",
            "Completed in 2m 27s\n",
            "-------------------epoch 10 -------------------\n",
            "train Loss: 0.1849, Accuracy: 94.59%\n",
            "val Loss: 0.2813, Accuracy: 91.18%\n",
            "Completed in 2m 24s\n",
            "-------------------epoch 11 -------------------\n",
            "train Loss: 0.1582, Accuracy: 95.30%\n",
            "val Loss: 0.2636, Accuracy: 91.79%\n",
            "Completed in 2m 28s\n",
            "-------------------epoch 12 -------------------\n",
            "train Loss: 0.1478, Accuracy: 95.73%\n",
            "val Loss: 0.2513, Accuracy: 92.00%\n",
            "Completed in 2m 29s\n",
            "-------------------epoch 13 -------------------\n",
            "train Loss: 0.1279, Accuracy: 96.58%\n",
            "val Loss: 0.2355, Accuracy: 92.74%\n",
            "Completed in 2m 26s\n",
            "-------------------epoch 14 -------------------\n",
            "train Loss: 0.1090, Accuracy: 96.77%\n",
            "val Loss: 0.2211, Accuracy: 93.19%\n",
            "Completed in 2m 29s\n",
            "-------------------epoch 15 -------------------\n",
            "train Loss: 0.1183, Accuracy: 96.43%\n",
            "val Loss: 0.2426, Accuracy: 92.20%\n",
            "Completed in 2m 29s\n",
            "-------------------epoch 16 -------------------\n",
            "train Loss: 0.1056, Accuracy: 96.94%\n",
            "val Loss: 0.2186, Accuracy: 92.99%\n",
            "Completed in 2m 24s\n",
            "-------------------epoch 17 -------------------\n",
            "train Loss: 0.0992, Accuracy: 97.01%\n",
            "val Loss: 0.2230, Accuracy: 92.79%\n",
            "Completed in 2m 27s\n",
            "-------------------epoch 18 -------------------\n",
            "train Loss: 0.0808, Accuracy: 97.85%\n",
            "val Loss: 0.2035, Accuracy: 93.27%\n",
            "Completed in 2m 24s\n",
            "-------------------epoch 19 -------------------\n",
            "train Loss: 0.0665, Accuracy: 98.26%\n",
            "val Loss: 0.1883, Accuracy: 94.17%\n",
            "Completed in 2m 26s\n",
            "-------------------epoch 20 -------------------\n",
            "train Loss: 0.0737, Accuracy: 97.83%\n",
            "val Loss: 0.2024, Accuracy: 93.40%\n",
            "Completed in 2m 23s\n",
            "-------------------epoch 21 -------------------\n",
            "train Loss: 0.0608, Accuracy: 98.36%\n",
            "val Loss: 0.1923, Accuracy: 94.02%\n",
            "Completed in 2m 26s\n",
            "-------------------epoch 22 -------------------\n",
            "train Loss: 0.0818, Accuracy: 97.58%\n",
            "val Loss: 0.2154, Accuracy: 93.17%\n",
            "Completed in 2m 23s\n",
            "-------------------epoch 23 -------------------\n",
            "train Loss: 0.0558, Accuracy: 98.61%\n",
            "val Loss: 0.1767, Accuracy: 94.37%\n",
            "Completed in 2m 13s\n",
            "-------------------epoch 24 -------------------\n",
            "train Loss: 0.0600, Accuracy: 98.27%\n",
            "val Loss: 0.1932, Accuracy: 93.92%\n",
            "Completed in 2m 9s\n",
            "-------------------epoch 25 -------------------\n",
            "train Loss: 0.0605, Accuracy: 98.25%\n",
            "val Loss: 0.1978, Accuracy: 93.63%\n",
            "Completed in 2m 4s\n",
            "-------------------epoch 26 -------------------\n",
            "train Loss: 0.0379, Accuracy: 99.02%\n",
            "val Loss: 0.1680, Accuracy: 94.77%\n",
            "Completed in 2m 7s\n",
            "-------------------epoch 27 -------------------\n",
            "train Loss: 0.0469, Accuracy: 98.82%\n",
            "val Loss: 0.1805, Accuracy: 94.32%\n",
            "Completed in 2m 8s\n",
            "-------------------epoch 28 -------------------\n",
            "train Loss: 0.0442, Accuracy: 98.88%\n",
            "val Loss: 0.1809, Accuracy: 94.50%\n",
            "Completed in 2m 5s\n",
            "-------------------epoch 29 -------------------\n",
            "train Loss: 0.0315, Accuracy: 99.34%\n",
            "val Loss: 0.1584, Accuracy: 95.08%\n",
            "Completed in 2m 6s\n",
            "-------------------epoch 30 -------------------\n",
            "train Loss: 0.0334, Accuracy: 99.22%\n",
            "val Loss: 0.1672, Accuracy: 94.68%\n",
            "Completed in 2m 3s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 전이학습"
      ],
      "metadata": {
        "id": "Q5E-8To9tZvV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 전이학습 모델 불러오기"
      ],
      "metadata": {
        "id": "kPQAR1pPtUWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([transforms.Resize([64,64]),\n",
        "          transforms.RandomHorizontalFlip(), transforms.RandomVerticalFlip(),\n",
        "          transforms.RandomCrop(52), transforms.ToTensor(),\n",
        "          transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225]) ]),\n",
        "    'val': transforms.Compose([transforms.Resize([64,64]), \n",
        "          transforms.RandomCrop(52), transforms.ToTensor(),\n",
        "          transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225]) ])\n",
        "}"
      ],
      "metadata": {
        "id": "_LfrBs6SsJB2"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = './splitted'\n",
        "image_datasets = {x: ImageFolder(root=os.path.join(data_dir,x),\n",
        "                                 transform=data_transforms[x]) for x in ['train','val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=4) for x in ['train','val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train','val']}\n",
        "\n",
        "class_names = image_datasets['train'].classes"
      ],
      "metadata": {
        "id": "pvFHB4oZwgyo"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "resnet = models.resnet50(pretrained=True)\n",
        "num_ftrs = resnet.fc.in_features\n",
        "resnet.fc = nn.Linear(num_ftrs, 33)\n",
        "resnet = resnet.to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, resnet.parameters()), lr=0.001)\n",
        "\n",
        "from torch.optim import lr_scheduler\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "pLWvH_AZxaYO"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ct = 0\n",
        "for child in resnet.children():\n",
        "  ct += 1\n",
        "  if ct < 6:\n",
        "    for param in child.parameters():\n",
        "      param.requires_grad = False"
      ],
      "metadata": {
        "id": "H4FSwGt5x9mr"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 전이학습 모델 수정 후 학습"
      ],
      "metadata": {
        "id": "uHdxENTE31x4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_resnet(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('--------------------- epoch {} ----------------------'.format(epoch+1))\n",
        "        since = time.time()\n",
        "        for phase in ['train','val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(DEVICE)\n",
        "                labels = labels.to(DEVICE)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "        \n",
        "                running_loss +=loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "      \n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss/dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double()/dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} ACC: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        time_elapsed = time.time() - since\n",
        "        print('Completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print(\"Best val Acc: {:.4f}\".format(best_acc))\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "xDrTulk3yu2M"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet50 = train_resnet(resnet, criterion, optimizer_ft,\n",
        "                              exp_lr_scheduler, num_epochs=EPOCH)\n",
        "\n",
        "torch.save(model_resnet50, 'resnet50.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4G5XjCT3MJR",
        "outputId": "30289dd4-cbef-4ec7-8607-72ef4d2bc12a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------- epoch 1 ----------------------\n",
            "train Loss: 0.5102 ACC: 0.8448\n",
            "val Loss: 0.2430 ACC: 0.9221\n",
            "Completed in 1m 24s\n",
            "--------------------- epoch 2 ----------------------\n",
            "train Loss: 0.2011 ACC: 0.9359\n",
            "val Loss: 0.1801 ACC: 0.9415\n",
            "Completed in 1m 25s\n",
            "--------------------- epoch 3 ----------------------\n",
            "train Loss: 0.1321 ACC: 0.9567\n",
            "val Loss: 0.2047 ACC: 0.9348\n",
            "Completed in 1m 29s\n",
            "--------------------- epoch 4 ----------------------\n",
            "train Loss: 0.1189 ACC: 0.9603\n",
            "val Loss: 0.1403 ACC: 0.9582\n",
            "Completed in 1m 31s\n",
            "--------------------- epoch 5 ----------------------\n",
            "train Loss: 0.1020 ACC: 0.9667\n",
            "val Loss: 0.1260 ACC: 0.9587\n",
            "Completed in 1m 27s\n",
            "--------------------- epoch 6 ----------------------\n",
            "train Loss: 0.0851 ACC: 0.9716\n",
            "val Loss: 0.0984 ACC: 0.9695\n",
            "Completed in 1m 25s\n",
            "--------------------- epoch 7 ----------------------\n",
            "train Loss: 0.0806 ACC: 0.9738\n",
            "val Loss: 0.1013 ACC: 0.9695\n",
            "Completed in 1m 25s\n",
            "--------------------- epoch 8 ----------------------\n",
            "train Loss: 0.0391 ACC: 0.9874\n",
            "val Loss: 0.0454 ACC: 0.9845\n",
            "Completed in 1m 25s\n",
            "--------------------- epoch 9 ----------------------\n",
            "train Loss: 0.0261 ACC: 0.9913\n",
            "val Loss: 0.0379 ACC: 0.9880\n",
            "Completed in 1m 25s\n",
            "--------------------- epoch 10 ----------------------\n",
            "train Loss: 0.0205 ACC: 0.9932\n",
            "val Loss: 0.0327 ACC: 0.9894\n",
            "Completed in 1m 25s\n",
            "--------------------- epoch 11 ----------------------\n",
            "train Loss: 0.0191 ACC: 0.9940\n",
            "val Loss: 0.0314 ACC: 0.9897\n",
            "Completed in 1m 26s\n",
            "--------------------- epoch 12 ----------------------\n",
            "train Loss: 0.0151 ACC: 0.9952\n",
            "val Loss: 0.0303 ACC: 0.9917\n",
            "Completed in 1m 25s\n",
            "--------------------- epoch 13 ----------------------\n",
            "train Loss: 0.0149 ACC: 0.9947\n",
            "val Loss: 0.0292 ACC: 0.9915\n",
            "Completed in 1m 25s\n",
            "--------------------- epoch 14 ----------------------\n",
            "train Loss: 0.0143 ACC: 0.9954\n",
            "val Loss: 0.0264 ACC: 0.9911\n",
            "Completed in 1m 25s\n",
            "--------------------- epoch 15 ----------------------\n",
            "train Loss: 0.0122 ACC: 0.9964\n",
            "val Loss: 0.0269 ACC: 0.9897\n",
            "Completed in 1m 25s\n",
            "--------------------- epoch 16 ----------------------\n",
            "train Loss: 0.0105 ACC: 0.9968\n",
            "val Loss: 0.0303 ACC: 0.9900\n",
            "Completed in 1m 26s\n",
            "--------------------- epoch 17 ----------------------\n",
            "train Loss: 0.0121 ACC: 0.9957\n",
            "val Loss: 0.0267 ACC: 0.9911\n",
            "Completed in 1m 25s\n",
            "--------------------- epoch 18 ----------------------\n",
            "train Loss: 0.0112 ACC: 0.9965\n",
            "val Loss: 0.0291 ACC: 0.9909\n",
            "Completed in 1m 25s\n",
            "--------------------- epoch 19 ----------------------\n",
            "train Loss: 0.0108 ACC: 0.9967\n",
            "val Loss: 0.0247 ACC: 0.9926\n",
            "Completed in 1m 25s\n",
            "--------------------- epoch 20 ----------------------\n",
            "train Loss: 0.0108 ACC: 0.9966\n",
            "val Loss: 0.0259 ACC: 0.9917\n",
            "Completed in 1m 25s\n",
            "--------------------- epoch 21 ----------------------\n",
            "train Loss: 0.0105 ACC: 0.9967\n",
            "val Loss: 0.0246 ACC: 0.9927\n",
            "Completed in 1m 24s\n",
            "--------------------- epoch 22 ----------------------\n",
            "train Loss: 0.0107 ACC: 0.9966\n",
            "val Loss: 0.0238 ACC: 0.9921\n",
            "Completed in 1m 25s\n",
            "--------------------- epoch 23 ----------------------\n",
            "train Loss: 0.0101 ACC: 0.9970\n",
            "val Loss: 0.0242 ACC: 0.9922\n",
            "Completed in 1m 25s\n",
            "--------------------- epoch 24 ----------------------\n",
            "train Loss: 0.0097 ACC: 0.9967\n",
            "val Loss: 0.0234 ACC: 0.9929\n",
            "Completed in 1m 25s\n",
            "--------------------- epoch 25 ----------------------\n",
            "train Loss: 0.0101 ACC: 0.9968\n",
            "val Loss: 0.0272 ACC: 0.9917\n",
            "Completed in 1m 24s\n",
            "--------------------- epoch 26 ----------------------\n",
            "train Loss: 0.0100 ACC: 0.9968\n",
            "val Loss: 0.0257 ACC: 0.9926\n",
            "Completed in 1m 24s\n",
            "--------------------- epoch 27 ----------------------\n",
            "train Loss: 0.0101 ACC: 0.9967\n",
            "val Loss: 0.0251 ACC: 0.9922\n",
            "Completed in 1m 24s\n",
            "--------------------- epoch 28 ----------------------\n",
            "train Loss: 0.0095 ACC: 0.9969\n",
            "val Loss: 0.0308 ACC: 0.9887\n",
            "Completed in 1m 24s\n",
            "--------------------- epoch 29 ----------------------\n",
            "train Loss: 0.0097 ACC: 0.9968\n",
            "val Loss: 0.0259 ACC: 0.9924\n",
            "Completed in 1m 24s\n",
            "--------------------- epoch 30 ----------------------\n",
            "train Loss: 0.0098 ACC: 0.9968\n",
            "val Loss: 0.0263 ACC: 0.9932\n",
            "Completed in 1m 24s\n",
            "Best val Acc: 0.9932\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 전이학습 평가하기"
      ],
      "metadata": {
        "id": "vSrQ1WEm35Ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_resNet = transforms.Compose([\n",
        "    transforms.Resize([64, 64]),\n",
        "    transforms.RandomCrop(52),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225])\n",
        "    ])\n",
        "\n",
        "test_resNet = ImageFolder(root='./splitted/test', transform=transform_resNet)\n",
        "test_loader_resNet = torch.utils.data.DataLoader(test_resNet,\n",
        "                                                 batch_size=BATCH_SIZE,\n",
        "                                                 shuffle=True,\n",
        "                                                 num_workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "5CcefJmK36a5",
        "outputId": "17f3c45d-3d37-4b24-be3e-a62478389a70"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-0d52aff17f2f>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     ])\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtest_resNet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./splitted/test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_resNet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m test_loader_resNet = torch.utils.data.DataLoader(test_resNet,\n\u001b[1;32m     10\u001b[0m                                                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     ):\n\u001b[0;32m--> 309\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;31m# is potentially overridden and thus could have a different logic.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The class_to_idx parameter cannot be None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mextensions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"Supported extensions are: {extensions if isinstance(extensions, str) else ', '.join(extensions)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Found no valid file for the classes Apple___Apple_scab, Apple___Black_rot, Apple___Cedar_apple_rust, Apple___healthy, Cherry___Powdery_mildew, Cherry___healthy, Corn___Cercospora_leaf_spot Gray_leaf_spot, Corn___Common_rust, Corn___Northern_Leaf_Blight, Corn___healthy, Grape___Black_rot, Grape___Esca_(Black_Measles), Grape___Leaf_blight_(Isariopsis_Leaf_Spot), Grape___healthy, Peach___Bacterial_spot, Peach___healthy, Pepper,_bell___Bacterial_spot, Pepper,_bell___healthy, Potato___Early_blight, Potato___Late_blight, Potato___healthy, Strawberry___Leaf_scorch, Strawberry___healthy, Tomato___Bacterial_spot, Tomato___Early_blight, Tomato___Late_blight, Tomato___Leaf_Mold, Tomato___Septoria_leaf_spot, Tomato___Spider_mites Two-spotted_spider_mite, Tomato___Target_Spot, Tomato___Tomato_Yellow_Leaf_Curl_Virus, Tomato___Tomato_mosaic_virus, Tomato___healthy. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50=torch.load('resnet50.pt')\n",
        "resnet50.eval()\n",
        "test_loss, test_accuracy = evaluate(resnet50, test_loader_resNet)\n",
        "\n",
        "print('ResNet test acc: ', test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "Otun9x_M4f7n",
        "outputId": "8f75086a-8c69-4294-f06e-533339d7f849"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-13fb6e914f73>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'resnet50.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader_resNet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ResNet test acc: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_loader_resNet' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UnvQf0dD8dFu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}